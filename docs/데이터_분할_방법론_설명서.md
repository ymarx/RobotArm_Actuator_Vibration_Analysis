# 데이터 분할 방법론 - 초보자를 위한 완벽 가이드

**작성일**: 2025-11-20
**대상**: 머신러닝 초보자
**목적**: 본 프로젝트에서 사용된 데이터 처리 및 분할 방법 완전 이해

---

## 📚 목차

1. [기본 개념: 원본 데이터에서 모델까지](#1-기본-개념-원본-데이터에서-모델까지)
2. [Step 1: 윈도우 슬라이딩이란?](#2-step-1-윈도우-슬라이딩이란)
3. [Step 2: 데이터 분할 전략](#3-step-2-데이터-분할-전략)
4. [Step 3: 시간분할 vs 파일분할](#4-step-3-시간분할-vs-파일분할)
5. [실제 프로젝트 적용 예시](#5-실제-프로젝트-적용-예시)
6. [왜 이렇게 복잡한가?](#6-왜-이렇게-복잡한가)

---

## 1. 기본 개념: 원본 데이터에서 모델까지

### 1.1 전체 프로세스 개요

```
┌─────────────────┐
│  원본 CSV 파일   │  61개 파일 (각 파일 = 한 번의 측정)
│  (~30-70초)     │  예: 100W_Sample00 ccw4_2025-11-07.csv
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  품질 검사       │  → 4개 파일 제외 (길이 부족, 노이즈 등)
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  57개 파일 사용  │  Normal: 11개, Abnormal: 46개
└────────┬────────┘
         │
         ▼  [Step 1: 윈도우 슬라이딩]
┌─────────────────┐
│  898개 윈도우    │  각 파일 → 여러 개의 8초 윈도우로 분할
│  (8초 조각들)    │  Normal: 392개, Abnormal: 506개
└────────┬────────┘
         │
         ▼  [Step 2: 데이터 분할]
┌─────────────────┐
│ Train/Val/Test  │  Train: 695, Val: 92, Test: 111
│   분할 완료      │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  머신러닝 모델   │  XGBoost 학습 및 평가
│   학습/평가      │
└─────────────────┘
```

### 1.2 용어 정리

| 용어 | 설명 | 예시 |
|------|------|------|
| **원본 파일** | 한 번의 측정으로 얻은 전체 데이터 | `100W_Sample00 ccw4.csv` (50초) |
| **윈도우** | 원본을 작은 시간 단위로 자른 조각 | 8초짜리 조각 하나 |
| **윈도우 슬라이딩** | 원본을 겹치면서 자르는 방법 | 50% 오버랩 = 4초씩 이동하며 자르기 |
| **파일분할** | 파일 단위로 Train/Val/Test 나누기 | 파일 A → Train, 파일 B → Test |
| **시간분할** | 파일 내부를 시간으로 나누기 | 0-60% → Train, 60-80% → Val, 80-100% → Test |
| **데이터 누수** | Test 데이터가 Train에 포함되는 치명적 오류 | 같은 파일의 윈도우가 Train과 Test에 동시 존재 |

---

## 2. Step 1: 윈도우 슬라이딩이란?

### 2.1 왜 필요한가?

**문제점**: 원본 파일이 너무 길다
- 100W 파일: 약 50-60초 (25,000~30,000개 샘플)
- 200W 파일: 약 60-70초 (32,000~36,000개 샘플)
- 이렇게 긴 데이터를 통째로 학습하면:
  - 모델이 패턴을 학습하기 어려움
  - 샘플 수가 너무 적음 (57개 파일만으로는 부족)

**해결책**: 긴 데이터를 짧은 조각으로 자르기
- 8초 단위로 자르면: 국소적 패턴 포착 가능
- 샘플 수 증가: 57개 파일 → 898개 윈도우

### 2.2 윈도우 슬라이딩 동작 원리

#### 예시: 100W_S00_CW 파일 (50초, 25,600 샘플)

**설정**:
- 윈도우 크기: 8초 = 4,096 샘플 (512 Hz × 8초)
- 오버랩: 50% = 4초 = 2,048 샘플

**슬라이딩 과정**:

```
원본 파일 (50초):
|━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━|
0초                        25초                        50초

윈도우 1:
|████████|
0━━━━━━8초

윈도우 2: (4초 이동)
    |████████|
    4━━━━━━12초

윈도우 3: (4초 이동)
        |████████|
        8━━━━━━16초

...계속...

윈도우 N:
                                              |████████|
                                              42━━━━━━50초
```

**결과**: 50초 파일 → 약 11개의 8초 윈도우

#### 오버랩이 필요한 이유

**오버랩 없이 (0%)** - 비효율적:
```
|████████|        |████████|        |████████|
0━━━━━━8초    8━━━━━━16초   16━━━━━━24초
                     ↑
            경계 부분의 패턴을 놓칠 수 있음
```

**50% 오버랩** - 효율적:
```
|████████|
    |████████|
        |████████|
0   4   8   12  16초
     ↑
 모든 시점이 2번 이상 포함됨 → 경계 패턴도 포착
```

### 2.3 실제 코드 예시 (개념)

```python
# 의사 코드 (실제와 유사)
def sliding_window(signal, window_size=4096, overlap=0.5):
    """
    signal: 원본 신호 (예: 25,600개 샘플)
    window_size: 윈도우 크기 (4,096 샘플 = 8초)
    overlap: 겹침 비율 (0.5 = 50%)
    """
    step = int(window_size * (1 - overlap))  # 2,048 샘플 = 4초

    windows = []
    for start in range(0, len(signal) - window_size + 1, step):
        end = start + window_size
        window = signal[start:end]  # 8초 조각 추출
        windows.append(window)

    return windows

# 예시
# 입력: 50초 파일 (25,600 샘플)
# 출력: 11개 윈도우 (각 4,096 샘플)
```

### 2.4 본 프로젝트 윈도우 슬라이딩 결과

| 파일 종류 | 파일 수 | 총 윈도우 수 | 파일당 평균 |
|----------|--------|------------|-----------|
| Normal | 11개 | 392개 | ~36개/파일 |
| Abnormal | 46개 | 506개 | ~11개/파일 |
| **전체** | **57개** | **898개** | **~16개/파일** |

**주의**:
- Normal 파일이 더 길어서 윈도우가 많음 (특히 200W_S02_CW: 167개!)
- Abnormal 파일은 비교적 짧음

---

## 3. Step 2: 데이터 분할 전략

### 3.1 Train/Validation/Test란?

머신러닝 모델 학습을 위해서는 데이터를 3개 세트로 나눕니다:

```
┌─────────────────────────────────────────────────────┐
│              전체 데이터 (898개 윈도우)              │
└─────────────────────────────────────────────────────┘
         │                │              │
         ▼                ▼              ▼
   ┌─────────┐      ┌─────────┐    ┌─────────┐
   │  Train  │      │   Val   │    │  Test   │
   │ 695개   │      │  92개   │    │ 111개   │
   │  77%    │      │  10%    │    │  13%    │
   └─────────┘      └─────────┘    └─────────┘
       │                │              │
       ▼                ▼              ▼
   모델 학습        하이퍼파라미터    최종 성능
   (공부하기)       튜닝(중간시험)    평가(기말시험)
```

### 3.2 각 세트의 역할

#### Train Set (훈련 세트) - 77%
**목적**: 모델 학습
- 모델이 이 데이터로 패턴을 학습
- "공부 자료" 역할

**비유**: 학생이 교과서와 문제집으로 공부

#### Validation Set (검증 세트) - 10%
**목적**: 모델 조정 (하이퍼파라미터 튜닝)
- 학습 중간에 모델 성능 확인
- 과적합(암기) 감지
- 최적의 모델 설정 찾기

**비유**: 모의고사로 실력 확인하고 공부 방법 조정

#### Test Set (테스트 세트) - 13%
**목적**: 최종 성능 평가
- 모델이 **절대 본 적 없는** 데이터
- 실전 성능 측정
- **한 번만 평가** (여러 번 보면 누수 발생)

**비유**: 실제 기말고사

### 3.3 데이터 누수 (Data Leakage)란?

**가장 치명적인 실수**: Test 데이터가 Train에 포함되는 것

#### 잘못된 예시 (데이터 누수 발생):
```
파일 A (100W_S00_CW, 20개 윈도우):
├─ 윈도우 1-10  → Train
├─ 윈도우 11-15 → Val
└─ 윈도우 16-20 → Test

문제: 윈도우들이 50% 겹침!
- 윈도우 10 (36~44초)과 윈도우 11 (40~48초)은 4초 겹침
- Train의 윈도우 10과 Val의 윈도우 11이 같은 신호 공유
- 모델이 "답을 미리 봄" = 부정행위!
```

#### 올바른 예시 (누수 방지):
```
방법 1: 파일 단위 분할
- 파일 A 전체 → Train
- 파일 B 전체 → Val
- 파일 C 전체 → Test
→ 파일 간 완전 독립!

방법 2: 시간 단위 분할 (같은 파일 내)
- 파일 A의 0-60% 시간 → Train
- 파일 A의 60-80% 시간 → Val
- 파일 A의 80-100% 시간 → Test
→ 시간 순서 보장, 겹침 없음
```

---

## 4. Step 3: 시간분할 vs 파일분할

### 4.1 왜 두 가지 방법을 혼용하는가?

**문제**: Normal 파일이 너무 적다 (11개뿐)

#### 만약 모든 파일을 파일분할로 처리하면:
```
Normal 11개 파일:
├─ Train: 7-8개 파일
├─ Val: 1-2개 파일
└─ Test: 1-2개 파일

문제점:
- Val과 Test에 각각 1-2개 파일만 할당
- Val Normal: 20-40개 윈도우 (너무 적음!)
- Test Normal: 20-40개 윈도우 (평가 신뢰도 낮음)
```

#### 해결책: 혼합 분할 전략 (Hybrid Split)
```
Normal 11개 파일:
├─ 시간분할 (4개): 100W_S00(CCW,CW), 200W_S03(CCW,CW)
│   → 각 파일을 시간으로 나눔 (0-60% Train, 60-80% Val, 80-100% Test)
│   → Val/Test에 각 파일의 일부 포함 → 샘플 수 증가!
│
└─ 파일분할 (7개): 100W_S01/S05/S06, 200W_S02
    → 각 파일 전체를 한 세트에 할당
    → Train에 집중 배치

Abnormal 46개 파일:
└─ 파일분할 (전체): 충분히 많으므로 파일 단위로만 분할
```

### 4.2 시간분할 상세 설명

#### 예시: 100W_S00_CW 파일 (50초, 20개 윈도우)

**원본 파일 시간 구간**:
```
|━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━|
0초        10        20        30        40        50초
|
0%        20%       40%       60%       80%      100%
```

**60-0-80-0-100% 분할 기준**:
```
├─────────── Train ─────────┤─ Val ─┤──── Test ────┤
0%                         60%     80%            100%
0초                        30초    40초            50초
```

**윈도우 슬라이딩 후 윈도우 배치**:
```
윈도우 1 (0-8초):   시작 0초  → 0%   → Train
윈도우 2 (4-12초):  시작 4초  → 8%   → Train
윈도우 3 (8-16초):  시작 8초  → 16%  → Train
...
윈도우 8 (28-36초): 시작 28초 → 56%  → Train
윈도우 9 (32-40초): 시작 32초 → 64%  → Val  ← 60% 넘음!
윈도우 10(36-44초): 시작 36초 → 72%  → Val
윈도우 11(40-48초): 시작 40초 → 80%  → Test ← 80% 넘음!
윈도우 12(44-50초): 시작 44초 → 88%  → Test
```

**결과**:
- Train: 18개 윈도우 (0-30초 구간)
- Val: 1개 윈도우 (30-40초 구간)
- Test: 1개 윈도우 (40-50초 구간)

**중요 원칙**:
1. **윈도우 시작 시간**의 비율로 판단 (끝 시간 아님!)
2. **시간 순서 보장**: Train → Val → Test 순서 엄격히 유지
3. **완전 분리**: Train의 마지막 윈도우(28-36초)와 Val의 첫 윈도우(32-40초)가 4초 겹치지만, 시작 시간 기준으로 명확히 구분됨

### 4.3 파일분할 상세 설명

#### 예시: Abnormal 파일들 (46개)

**분할 방법**:
```python
# 의사 코드
abnormal_files = 46개

# 제품별 분리 (100W, 200W)
# Random seed 42로 재현 가능하게
np.random.seed(42)

for product in [100W, 200W]:
    files = get_abnormal_files(product)

    # 70-15-15 비율로 분할
    train_files = random_select(files, ratio=0.7)  # 70%
    val_files = random_select(files, ratio=0.15)   # 15%
    test_files = remaining_files                    # 15%
```

**결과**:
- Abnormal Train: ~32개 파일 → 321개 윈도우
- Abnormal Val: ~7개 파일 → 88개 윈도우
- Abnormal Test: ~7개 파일 → 97개 윈도우

**핵심**:
- 각 파일의 **모든 윈도우**가 한 세트에만 속함
- 파일 A의 윈도우는 **절대** Train과 Test에 동시 존재 불가

---

## 5. 실제 프로젝트 적용 예시

### 5.1 최종 데이터 분할 결과

| 세트 | 전체 윈도우 | Normal | Abnormal | Normal 비율 |
|------|-----------|--------|----------|------------|
| **Train** | 695 | 374 | 321 | 53.8% |
| **Val** | 92 | 4 | 88 | 4.3% |
| **Test** | 111 | 14 | 97 | 12.6% |

### 5.2 Normal Train 374개의 구성

#### 시간분할 4개 파일 → 80개 윈도우
```
100W_S00_CCW_R4: 31개 (전체 33개 중 0-60% 구간)
100W_S00_CW_R4:  18개 (전체 20개 중 0-60% 구간)
200W_S03_CCW_R4: 3개  (전체 5개 중 0-60% 구간)
200W_S03_CW_R4:  28개 (전체 30개 중 0-60% 구간)
```

#### 파일분할 7개 파일 → 294개 윈도우
```
100W_S01_CCW_R4: 25개 (파일 전체)
100W_S01_CW_R4:  21개 (파일 전체)
100W_S05_CCW_R4: 18개 (파일 전체)
100W_S05_CW_R4:  17개 (파일 전체)
100W_S06_CCW_R4: 10개 (파일 전체)
100W_S06_CW_R4:  46개 (파일 전체)
200W_S02_CW_R4:  167개 (파일 전체) ← 가장 긴 파일!
```

### 5.3 Normal 파일이 11개인 이유

**질문 1**: "시료 번호 S00, S03만 양품인데 어떻게 11개 파일이 나오나요?"

**답변**:
실제 분석 결과 **추가 양품이 발견**되었습니다:

| 제품 | 시료 | CW | CCW | 소계 | 비고 |
|------|------|----|----|------|------|
| 100W | S00 | ✅ | ✅ | 2개 | 초기 양품 |
| 100W | S01 | ✅ | ✅ | 2개 | **추가 발견** |
| 100W | S05 | ✅ | ✅ | 2개 | **추가 발견** |
| 100W | S06 | ✅ | ✅ | 2개 | **추가 발견** |
| 200W | S02 | ✅ | ❌ | 1개 | **CW만 양품** |
| 200W | S03 | ✅ | ✅ | 2개 | 초기 양품 |
| **합계** | **6개 시료** | **9개** | **8개** | **11개** | |

**발견 경위**:
1. **초기 판정** (시험전): S00, S03만 양품
2. **EDA 단계**: 진동 분석 결과 S01, S05, S06도 정상 범위
3. **전문가 재검토**: CSV의 `Command` 필드 확인 ("정상" 표기)
4. **Phase 3 확정**: 11개 파일을 Normal로 최종 판정

**특이사항**:
- 200W_S02_CCW는 없거나 품질 불합격
- 200W_S02_CW만 Normal로 사용 (매우 긴 파일, 167개 윈도우)

### 5.4 Normal 윈도우가 392개나 되는 이유

**질문 2**: "1파일 60초면 11개 윈도우인데, 왜 300개가 넘나요?"

**답변**: 파일마다 **길이가 다르고**, 특히 200W_S02_CW가 매우 길기 때문입니다.

#### 실제 파일 길이 및 윈도우 개수

| 파일 | 원본 길이 | 윈도우 개수 | 설명 |
|------|----------|-----------|------|
| 200W_S02_CW | **~672초 (11분!)** | **167개** | 비정상적으로 긴 측정 |
| 100W_S06_CW | ~192초 | 46개 | 100W 중 가장 긴 파일 |
| 100W_S00_CCW | ~138초 | 33개 | 평균보다 긴 파일 |
| 100W_S01_CCW | ~108초 | 25개 | 평균적인 100W 파일 |
| 200W_S03_CCW | ~28초 | 5개 | 매우 짧은 파일 |

**윈도우 계산 공식**:
```
윈도우_개수 = floor((파일_길이_초 - 8) / 4) + 1

예시:
- 672초 파일: (672 - 8) / 4 + 1 = 167개 ✅
- 60초 파일: (60 - 8) / 4 + 1 = 14개
- 50초 파일: (50 - 8) / 4 + 1 = 11개 ✅ (질문의 예시)
```

#### Normal 392개 윈도우 구성

```
200W_S02_CW:  167개 (42.6%)  ← 이 파일 하나가 전체의 40% 이상!
100W_S06_CW:   46개 (11.7%)
100W_S00_CCW:  33개 (8.4%)
200W_S03_CW:   30개 (7.7%)
100W_S01_CCW:  25개 (6.4%)
100W_S01_CW:   21개 (5.4%)
100W_S00_CW:   20개 (5.1%)
100W_S05_CCW:  18개 (4.6%)
100W_S05_CW:   17개 (4.3%)
100W_S06_CCW:  10개 (2.6%)
200W_S03_CCW:   5개 (1.3%)
-----------------------------------
합계:         392개 (100%)
```

**핵심 포인트**:
- 200W_S02_CW 파일 하나가 167개 윈도우 생성 (전체의 43%)
- 이 파일은 **품질 검사에서 "비정상적으로 긺"으로 플래그**되었으나,
- 데이터 자체는 정상(Normal)이므로 분석에 포함됨
- 11개 파일 평균: 35.6개/파일 (60초 기준 11개보다 3배 많음)

---

## 6. 왜 이렇게 복잡한가?

### 6.1 각 단계의 필요성

#### 윈도우 슬라이딩을 하는 이유
1. **샘플 수 부족 해결**: 57개 → 898개
2. **국소 패턴 학습**: 8초 단위 진동 패턴 포착
3. **데이터 증강**: 50% 오버랩으로 경계 패턴도 학습

#### 시간분할을 사용하는 이유
1. **Normal 샘플 부족 해결**: Val/Test에도 Normal 포함
2. **시간 순서 보장**: 미래 데이터로 과거 예측 방지
3. **데이터 누수 방지**: 시간 구간 완전 분리

#### 파일분할을 사용하는 이유
1. **완전한 독립성**: 파일 간 정보 공유 없음
2. **실전 환경 시뮬레이션**: 새로운 제품 평가와 유사
3. **Abnormal 충분**: 46개 파일로 충분한 분할 가능

### 6.2 혼합 전략의 장점

| 전략 | 장점 | 단점 | 적용 대상 |
|------|------|------|----------|
| **시간분할** | Val/Test 샘플 확보 | 시간 구간 설정 필요 | Normal 4개 파일 |
| **파일분할** | 완전 독립성 | 파일 수 많이 필요 | Normal 7개 + Abnormal 46개 |
| **혼합** | 두 장점 결합 | 복잡함 | 본 프로젝트 |

### 6.3 데이터 누수 방지 검증

본 프로젝트에서 수행한 검증:

```python
# Phase 3-0: Data Integrity Audit에서 수행
검증 1: 파일 간 중복 확인
→ ✅ 통과: 시간분할 4개 제외, 모든 파일이 단일 세트에만 속함

검증 2: 시간 경계 준수 확인
→ ✅ 통과: Train(0-60%), Val(60-80%), Test(80-100%) 엄격히 분리

검증 3: GroupKFold 누수 방지
→ ✅ 통과: StratifiedGroupKFold로 같은 파일의 윈도우 그룹화
```

---

## 7. 요약 및 핵심 포인트

### 7.1 전체 프로세스 요약

```
61개 원본 CSV 파일
    ↓ (품질 검사)
57개 사용 파일 (Normal 11개, Abnormal 46개)
    ↓ (윈도우 슬라이딩: 8초, 50% 오버랩)
898개 윈도우 (Normal 392개, Abnormal 506개)
    ↓ (혼합 분할 전략)
Train: 695개 (Normal 374, Abnormal 321)
Val:   92개  (Normal 4, Abnormal 88)
Test:  111개 (Normal 14, Abnormal 97)
```

### 7.2 핵심 개념 정리

1. **윈도우 슬라이딩**: 긴 파일 → 짧은 조각들 (샘플 수 증가)
2. **50% 오버랩**: 경계 패턴 포착 + 데이터 증강
3. **시간분할**: Normal 부족 해결 (4개 파일만)
4. **파일분할**: 완전 독립성 보장 (대부분 파일)
5. **데이터 누수 방지**: Train/Val/Test 완전 분리

### 7.3 주의해야 할 함정

❌ **하지 말아야 할 것**:
- 윈도우를 무작위로 Train/Test에 배치 (누수!)
- 시간 순서 무시 (미래로 과거 예측)
- Test 데이터로 여러 번 평가 (간접 누수)
- Val/Test Normal이 0개 (평가 불가)

✅ **해야 할 것**:
- 파일 단위 또는 시간 단위 분할
- 시간 순서 엄격히 보장
- Test는 최종 1회만 평가
- 모든 세트에 Normal 포함

---

## 8. 추가 자료

### 8.1 관련 문서

- `docs/data_validation_report.md`: 데이터 누수 검증 상세
- `docs/phase3_results/phase3_0_audit/data_integrity_audit.md`: 최종 검증 결과
- `docs/프로젝트_종합_분석_보고서.md`: 전체 프로젝트 요약

### 8.2 코드 참조

- `scripts/step1_rms_threshold_experiment.py`: 윈도우 슬라이딩 구현
- `phase3/phase3_0_data_leakage_audit.py`: 데이터 누수 검증 코드
- `phase3/phase3_1_xgboost_core_band_rms.py`: StratifiedGroupKFold 사용

### 8.3 시각화

```
윈도우 슬라이딩 시각화:
docs/eda_results/window_sliding_visualization.png (있다면)

데이터 분할 시각화:
docs/phase3_results/phase3_0_audit/split_distribution.png (있다면)
```

---

**작성자**: Claude Code
**검토일**: 2025-11-20
**버전**: 1.0
